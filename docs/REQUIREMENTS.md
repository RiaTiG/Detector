# Требования к системе AI Text Detector

## 1. Функциональные требования (FR - Functional Requirements)

### FR-1: Обучение моделей

#### FR-1.1: Загрузка обучающих данных
- Система должна поддерживать загрузку данных из следующих источников:
  - Директории с текстовыми файлами (разделение на `human/` и `ai/`)
  - CSV файлы с колонками `text` и `label` (0 = человек, 1 = AI)
  - Генерацию примеров для демонстрации
- Минимальный размер датасета: 50 текстов на каждый класс
- Рекомендуемый размер: 100+ текстов на класс

#### FR-1.2: Предобработка данных
- Система должна автоматически разделять данные на обучающую и тестовую выборки (по умолчанию 80/20)
- Валидация данных на наличие пустых текстов
- Проверка баланса классов с предупреждением при дисбалансе > 70/30

#### FR-1.3: Извлечение признаков
Система должна извлекать следующие группы признаков:

**Стилометрические признаки (минимум 6):**
- Средняя длина предложения
- Дисперсия длины предложения
- Type-Token Ratio (разнообразие лексики)
- Hapax legomena ratio (слова, встречающиеся один раз)
- Частота использования служебных слов
- Плотность пунктуации

**Синтаксические признаки (минимум 5):**
- Средняя глубина синтаксического дерева
- Дисперсия глубины дерева
- Паттерны расстановки запятых
- Длина зависимостей в дереве разбора
- Разнообразие частей речи

**Семантические признаки (минимум 5):**
- Плотность именованных сущностей
- Паттерны использования местоимений (первого лица)
- Частота отрицаний
- Использование модальных глаголов
- Соотношение прилагательных и существительных

#### FR-1.4: Обучение классификаторов
- Система должна поддерживать обучение двух типов моделей:
  - **XGBoost**: градиентный бустинг с настраиваемыми гиперпараметрами
  - **Neural Network**: многослойная нейронная сеть с dropout
- Возможность обучения обеих моделей одновременно для сравнения
- Автоматическая нормализация признаков (StandardScaler)

#### FR-1.5: Сохранение моделей
- Сохранение обученных моделей в директории `models/`
- Сохранение параметров нормализации (scaler)
- Сохранение метаданных модели (дата обучения, версия, параметры)

### FR-2: Детекция текстов

#### FR-2.1: Анализ текста
- Система должна принимать текст и возвращать:
  - **prediction**: 0 (человек) или 1 (AI)
  - **prediction_label**: "Human" или "AI-generated"
  - **confidence**: уверенность модели (0-1)
  - **ai_probability**: вероятность, что текст написан AI (0-1)
  - **human_probability**: вероятность, что текст написан человеком (0-1)

#### FR-2.2: Режимы ввода
- Анализ текста из командной строки (`--text`)
- Анализ текста из файла (`--file`)
- Интерактивный режим с вводом текста в консоли
- Программный API для интеграции

#### FR-2.3: Объяснение предсказаний
- Система должна предоставлять объяснение предсказания через метод `explain_prediction()`
- Вывод топ-N наиболее важных признаков, влияющих на решение
- Для каждого признака: название, значение, важность, вклад в предсказание

#### FR-2.4: Пакетная обработка
- Возможность анализа множества текстов за один запуск
- Экспорт результатов в CSV формат

### FR-3: Визуализация результатов

#### FR-3.1: Графики для обучения
Система должна генерировать следующие визуализации:
- **Feature Importance**: важность каждого признака
- **Confusion Matrix**: матрица ошибок классификации
- **ROC Curve**: ROC-кривая с показателем AUC
- **Feature Distributions**: распределения ключевых признаков для обоих классов
- **Model Comparison**: сравнение метрик разных моделей (если обучено несколько)

#### FR-3.2: Сохранение визуализаций
- Все графики сохраняются в директории `results/`
- Формат: PNG с разрешением не менее 300 DPI
- Автоматическая генерация после обучения

#### FR-3.3: Текстовые отчеты
- Генерация текстовых отчетов с метриками в `results/report.txt`
- Включение confusion matrix, classification report

### FR-4: Поддержка языков

#### FR-4.1: Многоязычность
- Поддержка английского языка (по умолчанию)
- Поддержка русского языка через параметр `--language ru`
- Автоматическая загрузка соответствующих языковых моделей

#### FR-4.2: Облегченный режим
- Режим без spaCy для совместимости с Python 3.14+
- Использование `feature_extractor_lite.py` при отсутствии spaCy
- Сохранение основной функциональности с ограниченным набором признаков

### FR-5: Интеграция и расширяемость

#### FR-5.1: Программный API
- Класс `AITextDetector` для использования в других приложениях
- Методы: `detect()`, `explain_prediction()`, `batch_detect()`
- Возможность загрузки сторонних обученных моделей

#### FR-5.2: Расширение признаков
- Архитектура позволяет добавление новых признаков без изменения основного кода
- Документированный интерфейс для кастомных feature extractors

#### FR-5.3: Настройка моделей
- Возможность изменения гиперпараметров через конфигурацию
- Параметры XGBoost: `n_estimators`, `max_depth`, `learning_rate`, `min_child_weight`
- Параметры Neural Network: `hidden_sizes`, `dropout`, `learning_rate`, `batch_size`, `epochs`

---

## 2. Нефункциональные требования (NFR - Non-Functional Requirements)

### NFR-1: Производительность

#### NFR-1.1: Скорость обучения
- Обучение XGBoost модели на 1000 текстов: не более 5 минут (на стандартном CPU)
- Обучение нейронной сети на 1000 текстов: не более 15 минут (на стандартном CPU)
- Извлечение признаков из одного текста (100-500 слов): не более 2 секунд

#### NFR-1.2: Скорость детекции
- Анализ одного текста (100-500 слов): не более 1 секунды
- Пакетная обработка 100 текстов: не более 30 секунд
- Загрузка модели в память: не более 2 секунд

#### NFR-1.3: Использование ресурсов
- Пиковое использование RAM при обучении: не более 2 GB
- Пиковое использование RAM при детекции: не более 500 MB
- Размер сохраненной модели XGBoost: не более 10 MB
- Размер сохраненной нейронной сети: не более 50 MB

### NFR-2: Надежность

#### NFR-2.1: Обработка ошибок
- Корректная обработка некорректного ввода (пустые тексты, спецсимволы)
- Информативные сообщения об ошибках
- Graceful degradation при отсутствии зависимостей (переход на lite режим)

#### NFR-2.2: Отказоустойчивость
- Система должна продолжать работу при отсутствии интернет-соединения
- Сохранение промежуточных результатов при обучении
- Возможность продолжения обучения с checkpoint

#### NFR-2.3: Валидация
- Проверка корректности загружаемых моделей
- Проверка совместимости версий моделей
- Валидация формата входных данных

### NFR-3: Удобство использования (Usability)

#### NFR-3.1: Простота установки
- Установка всех зависимостей одной командой `pip install -r requirements.txt`
- Автоматическая установка языковых моделей (опционально)
- Документированные требования к системе

#### NFR-3.2: Интерфейс командной строки
- Интуитивные команды и параметры
- Справка по всем командам через `--help`
- Прогресс-бары для длительных операций
- Цветной вывод для лучшей читаемости (опционально)

#### NFR-3.3: Документация
- Полное README с примерами использования
- Документация API в docstrings
- Примеры кода в `example.py`
- Быстрый старт в `QUICKSTART.md`

### NFR-4: Поддерживаемость (Maintainability)

#### NFR-4.1: Качество кода
- Модульная архитектура с разделением ответственности
- Соблюдение PEP 8 для Python кода
- Type hints для основных функций
- Комментарии для сложных алгоритмов

#### NFR-4.2: Тестирование
- Unit-тесты для критических компонентов
- Integration-тесты для пайплайна обучения
- Покрытие кода тестами не менее 60%

#### NFR-4.3: Версионирование
- Семантическое версионирование (SemVer)
- Changelog с описанием изменений
- Совместимость моделей между минорными версиями

### NFR-5: Переносимость (Portability)

#### NFR-5.1: Кроссплатформенность
- Работа на Windows, macOS, Linux
- Поддержка Python 3.8+
- Независимость от специфичных для платформы библиотек

#### NFR-5.2: Зависимости
- Минимальное количество обязательных зависимостей
- Использование стабильных версий библиотек
- Опциональные зависимости для расширенной функциональности

### NFR-6: Безопасность

#### NFR-6.1: Обработка данных
- Отсутствие отправки данных на внешние серверы
- Локальная обработка всех текстов
- Безопасное хранение моделей (без исполняемого кода)

#### NFR-6.2: Входные данные
- Защита от code injection через входные данные
- Ограничение максимального размера обрабатываемого текста
- Санитизация путей к файлам

### NFR-7: Масштабируемость

#### NFR-7.1: Объем данных
- Поддержка обучения на датасетах до 100,000 текстов
- Эффективная работа с текстами длиной до 10,000 слов
- Пакетная обработка неограниченного количества текстов (с ограничением памяти)

#### NFR-7.2: Расширяемость
- Возможность добавления новых типов классификаторов
- Возможность добавления новых групп признаков
- Поддержка кастомных пре- и постпроцессоров

---

## 3. Требования к точности (Accuracy Requirements)

### AR-1: Метрики качества классификации

#### AR-1.1: Минимальные метрики
На сбалансированном датасете (500+ текстов каждого класса):
- **Accuracy** ≥ 75% (общая точность классификации)
- **Precision** ≥ 70% (точность определения AI текстов)
- **Recall** ≥ 70% (полнота обнаружения AI текстов)
- **F1-Score** ≥ 70% (гармоническое среднее precision и recall)
- **AUC-ROC** ≥ 0.80 (площадь под ROC-кривой)

#### AR-1.2: Целевые метрики
Желаемые показатели на хорошо подготовленном датасете:
- **Accuracy** ≥ 85%
- **Precision** ≥ 82%
- **Recall** ≥ 82%
- **F1-Score** ≥ 82%
- **AUC-ROC** ≥ 0.90

#### AR-1.3: Метрики для специфичных случаев
- **Recall для AI текстов** ≥ 75% (важно не пропускать AI контент)
- **Precision для Human текстов** ≥ 80% (важно не ложно обвинять людей)

### AR-2: Устойчивость к различным типам текстов

#### AR-2.1: Длина текста
- **Короткие тексты (50-100 слов)**: Accuracy ≥ 65%
- **Средние тексты (100-500 слов)**: Accuracy ≥ 75%
- **Длинные тексты (500+ слов)**: Accuracy ≥ 80%

#### AR-2.2: Жанры текстов
Система должна поддерживать анализ следующих жанров с точностью ≥ 70%:
- Новостные статьи
- Академические тексты
- Блоги и посты в социальных сетях
- Техническая документация
- Креативное письмо (рассказы, эссе)

#### AR-2.3: Языки
- **Английский**: Accuracy ≥ 75%
- **Русский**: Accuracy ≥ 70% (с учетом меньшей зрелости языковых моделей)

### AR-3: Устойчивость к обфускации

#### AR-3.1: Простые модификации
Система должна сохранять точность ≥ 65% при следующих модификациях AI текста:
- Замена некоторых слов синонимами
- Изменение порядка предложений
- Добавление/удаление служебных слов

#### AR-3.2: Смешанные тексты
- **AI текст с 10-20% человеческих правок**: детекция как AI с confidence ≥ 60%
- **Человеческий текст с AI помощью**: детекция в зависимости от степени модификации

### AR-4: Калибровка уверенности

#### AR-4.1: Соответствие вероятностей
- Predicted probability должна коррелировать с реальной точностью (calibration)
- Expected Calibration Error (ECE) ≤ 0.15
- При confidence > 0.9, accuracy должна быть ≥ 85%
- При confidence < 0.6, система должна сообщать о низкой уверенности

#### AR-4.2: Пороги confidence
- **High confidence**: probability ≥ 0.85 (можно доверять предсказанию)
- **Medium confidence**: 0.65 ≤ probability < 0.85 (требуется осторожность)
- **Low confidence**: probability < 0.65 (результат ненадежен)

### AR-5: Воспроизводимость

#### AR-5.1: Детерминизм
- При фиксированном random seed результаты обучения должны быть идентичны
- Детекция одного и того же текста должна давать одинаковый результат

#### AR-5.2: Стабильность между версиями
- Метрики не должны деградировать более чем на 5% между минорными версиями
- Сохранение обратной совместимости для сохраненных моделей

### AR-6: Специфичные требования к признакам

#### AR-6.1: Информативность признаков
- Каждый признак должен иметь feature importance ≥ 0.01 (1%)
- Топ-10 признаков должны объяснять ≥ 60% предсказания
- Отсутствие признаков с нулевой вариативностью

#### AR-6.2: Робастность признаков
- Признаки должны быть устойчивы к минорным изменениям в тексте
- Variation coefficient признаков в пределах одного класса ≤ 50%

### AR-7: Тестирование качества

#### AR-7.1: Кросс-валидация
- 5-fold cross-validation: стандартное отклонение accuracy ≤ 5%
- Отсутствие overfitting: разница между train и test accuracy ≤ 10%

#### AR-7.2: Benchmarks
- Тестирование на публичных датасетах (если доступны)
- Сравнение с baseline моделями (например, простой Logistic Regression)
- XGBoost должен превосходить baseline на ≥ 10% по F1-Score

### AR-8: Ограничения и предупреждения

#### AR-8.1: Минимальные требования к данным
- Система должна предупреждать, если:
  - Текст содержит < 50 слов
  - Обучающий датасет < 100 примеров на класс
  - Дисбаланс классов > 70/30

#### AR-8.2: Граничные случаи
Система должна корректно обрабатывать:
- Тексты на смешанных языках (вывод предупреждения)
- Тексты со специальными символами, эмодзи
- Тексты с кодом или математическими формулами (предупреждение о возможной неточности)

---

## 4. Приоритизация требований

### Критические (Must Have)
- FR-1.3: Извлечение всех групп признаков
- FR-2.1: Базовая детекция текста
- AR-1.1: Минимальные метрики качества
- NFR-2.1: Обработка ошибок

### Важные (Should Have)
- FR-3.1: Визуализация результатов
- FR-4.1: Многоязычность
- AR-1.2: Целевые метрики
- NFR-1: Требования к производительности

### Желательные (Could Have)
- FR-2.4: Пакетная обработка
- FR-5.2: Расширение признаков
- AR-3: Устойчивость к обфускации
- NFR-7.2: Расширяемость

### Опциональные (Won't Have in MVP)
- Веб-интерфейс
- REST API
- Поддержка дополнительных языков (кроме EN/RU)
- Интеграция с облачными сервисами
